---
title: "class 9 ws"
author: "Nicholas Donahue"
date: "10/30/2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Unsupervised Learning Analysis of Cancer Cells
impot data. 
```{r}
url<-"https://bioboot.github.io/bimm143_S18/class-material/WisconsinCancer.csv"
wisc_df<-read.csv(url)
head(wisc_df)
nrow(wisc_df)
#count number of malignant and benign tumors
table(wisc_df$diagnosis)
as.numeric(wisc_df$diagnosis=="M")
```

Examine input data. convert other columns of data frame to matrix
```{r}
wisc.data<-as.matrix(wisc_df[,3:32])
```

counting number of malignant or benign tumors
```{r}
diagnosis<-as.numeric(wisc_df$diagnosis=="M")
sum(diagnosis)

```
How many variables/features in the data are suffixed with _mean? 10 of them
```{r}
x<-length(grep("_mean", colnames(wisc.data)))

```
There are are `r x` mean measurements in this dataset

```{r}
rownames(wisc.data)<-wisc_df$id
```
Secion 2
Performing PCA
Check the mean and SD of the features of wisc.data to determine if should be scaled
```{r}
colMeans(wisc.data)
```

```{r}
apply(wisc.data, 2, sd)
```

```{r}
#perform PCA on wisc.data
wisc.pr<-prcomp(wisc.data, scale=TRUE)
summary(wisc.pr)
```
Making a plot of PC1 vs PC2

```{r}
biplot(wisc.pr)
```
hard to understand. going to need a different plot
```{r}
attributes(wisc.pr)
```

```{r}
dim(wisc.pr$x)
```

```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2])
```

```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=diagnosis+1)

```

plot principal components 1 and 3
```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,3], col=diagnosis+1)

```
Overall plots indicate that principal component 1 is capturing sep of malignant from benign samples.

Variance Explained

```{r}
pr.var<-wisc.pr$sdev^2
pr.var
```

 dividing
```{r}
pve<-pr.var/sum(pr.var)
pve
```

Plotting scree plot
```{r}
plot(pve, xlab = "Principal Component", ylab="proportion of Variance explained", ylim=c(0, 1), type="o")
```
Barplot
```{r}
percentpve<-pve*100
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```

```{r}
plot(cumsum(pve), xlab = "Principal Component", 
     ylab = "Cumulative Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```

Section 3
Hierarchical Clustering

```{r}
data.scaled<-scale(wisc.data)

```

```{r}
data.dist<-dist(data.scaled)
```
Create hierarchical clustering model
```{r}
wisc.hclust<-hclust(data.dist, method="complete")
plot(wisc.hclust)
```
Use cutree() to cut tree so that it has 4 clusters
```{r}
plot(wisc.hclust)
wisc.hclust.clusters<-cutree(wisc.hclust, k=4)
table(wisc.hclust.clusters)
```
Compare cluster groups to show diagnosis

```{r}
table(wisc.hclust.clusters, diagnosis)
```

Trying to find a better diagnosis

```{r}
wisc.hclust.clusters6<-cutree(wisc.hclust, k=10)
table(wisc.hclust.clusters6, diagnosis)
```

Section 5: CLustering on PCA Results

```{r}
## Use the distance along the first 7 PCs for clustering i.e. wisc.pr$x[, 1:7]
d.pr<-dist(wisc.pr$x[,1:7])
wisc.pr.hclust<-hclust(d.pr, method="complete")
plot(wisc.pr.hclust)
```
Cut this hierarchical clustering model into 4 clusters and assign the results to wisc.pr.hclust.clusters.
```{r}
wisc.pr.hclust.clusters<-cutree(wisc.pr.hclust, k=4)
table(wisc.pr.hclust.clusters)
```
Using table(), compare the results from your new hierarchical clustering model with the actual diagnoses.

```{r}
table(wisc.pr.hclust.clusters, diagnosis)
```

##bonus: predictive modeling with PCA Components
Take new patient data and apply PCA model from above
```{r}
## Predicting Malignancy Of New samples
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
plot(wisc.pr$x[,1:2], col=diagnosis+1)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
```

